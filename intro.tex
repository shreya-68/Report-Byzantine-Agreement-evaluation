\section{Introduction}

The Distributed Consensus problem, introduced in 1980 by Pease et al. \cite{PeaseSL80}, is one of the most important and well-studied problems in distributed systems. In essence, the problem deals with multiple processes, each with an opinion initially, cooperating with each other to reach an agreement. The motivation for this problem arises from cases such as database transactions, where a number of systems need to agree on whether to commit or abort a transaction, or in aircraft controllers that need to agree on which plane should take-off or arrive first. In the latter case, in a safety-critical system such as this one, it is essential that aircraft controllers reach an agreement within a bounded period of time and all the controllers have the same decision, while in the former case, it is necessary that the systems eventually reach an agreement. Therefore, any consensus solving algorithm needs to satisfy certain correctness conditions that are formally given as follows:

\begin{itemize}
    \item \textit{Consistency}: All processes agree on the same value and all the decisions are final.
    \item \textit{Validity}: If all processes start with the same initial value $v$, then $v$ is the only allowable decision for all processes.
    \item \textit{Termination}: All processes eventually decide.
\end{itemize}

%TODO: give example of synchronous

These conditions also define the safety and liveness conditions that a distributed consensus algorithm must satisfy.  The consistency condition is a safety condition, and safety will be violated if any two processes decide on different values. The \textit{termination} condition specifies the liveness condition of the system. For a system to continue executing correctly until it terminates, all processes must eventually come to a conclusion.

In real-world applications, it would be unrealistic to assume that the systems involved in solving the problem will continue to work correctly, for the whole duration, as specified by the protocol. It might also be the case that communication links between systems break and the system \textit{partitions}, the network becomes congested due to too many requests, or the messages are not delivered in order. To achieve reliability in distributed systems, protocols are needed which enable the system as a whole to continue to function despite the failure of a limited number of components. Another challenge that real-world systems face is the problem of \textit{asynchronous} execution. Different components might face arbitrary, unbounded delays. However, in a synchronous setting, these delays are bounded and the bound is known. This allows all the components to execute in a lock-step manner. This simplifies the protocols, as steps can be taken just by observing the global clock. The asynchronous model is strictly harder than the synchronous model. 

It was shown in \cite{LamportSP82} that consensus can never be reached even between two processes if there is link failure. Under the assumption that the links do not display any kind of fault, one needs to analyze scenarios in the case of process failures. Generally, the kind of failures that a process can encounter is either a \textit{fail-stop} failure or a \textit{Byzantine failure}. Fail-stop failures occur when processes fail by stopping. While this is not a problem when processors are synchronous, distributed consensus becomes impossible in an asynchronous system with just one faulty process as was shown in the famous result by Fischer et al. \cite{FischerLP83}. In the case of a byzantine failure, the processes fail by acting maliciously. Depending on the ratio of faulty processes to all the processes, consensus may be impossible even when the system is synchronous. The problem of solving consensus in the presence of byzantine failures came to be known as the `Byzantine Agreement Problem' \cite{LamportSP82}. With the increasing number of malicious attacks reported in recent times, and software bugs, dealing with this problem has become more important than ever before.

A vast amount of work has been done over the years to solve the Byzantine Agreement Problem, and different approaches have been taken for various models of the problem. Randomized algorithms allowed us to overcome the barrier of the impossibility result in the asynchronous setting. Even in the synchronous setting, they provided major improvements from the deterministic algorithms by a factor polynomial in the size of the network. The probabilistic techniques provide an advantage - they allow us to eliminate the worst-case scenarios by giving them a probability of $0$ and a probability distribution is given to the other cases. While the literature is rich in theoretical results, there has been a lack of extensive practical results for the proposed algorithms. This can be largely attributed to the fact that simple algorithms are theoretically inefficient, while the more complex ones are hard to implement. Theoretical results give us information about the worst case scenarios, although practically, the system does not always run in the worst case. It would also be unrealistic to completely relax this assumption. Analysis techniques using the Big 'O' notation sometimes hide away large constants which are of significance when we look at memory or bandwidth consumption in a real-world application. Many complex algorithms make certain assumptions about systems, for example, the existence of a large fraction of faulty processes. Whereas there may actually only be a small fraction of faulty processes and in such cases the algorithm would be unnecessarily complex and inefficient.

Motivated by the need to analyze algorithms under such varying conditions, we evaluate the relative performance of three recently proposed solutions for the Byzantine Agreement problem when implemented on a cluster. Two of these are randomized algorithm - (1) by Ben-Or et al. \cite{BPV06}, which we call algorithm \textit{Quorum} throughout the paper, and (2) an almost-everywhere to everywhere algorithm by Braud-Santoni et al. \cite{BGH13} called algorithm \textit{Pull-Push} henceforth. The third is a deterministic algorithm due to Kowalski et al. \cite{KM13}, which we refer to as algorithm \textit{ImprovedEIG}. We vary two parameters to define the workload of the system - the number of processes, and with that the fraction of faults in the system. For evaluation, we use four metrics, two of which are commonly used for theoretical evaluation - communication complexity and round complexity, and the other two being time complexity and memory comsumption. We report on the behavior of the algorithms on varying the parameters and their effects on these metrics. 

The algorithm \textit{Pull-Push}, is one of the most recent and best known performing result in terms of communication complexity, known so far. The main contribution of the paper has been to give an almost everywhere to everywhere solution, which improves the amortized communication complexity to $\tilde{O}(1)$ per node, The previously best known result was $\tilde{O}(n^{1/2})$ given by \cite{KLST11}. The algorithm uses the model previously considered in \cite{KLST11,KSSV06,BPV06,KS09}, that of a synchronous, full-information model, with a non-adaptive adversary. They also show that similar results can be shown even in the case of an asynchronous model. Even though, the communication complexity result is the best known, there has been a trade-off with time complexity which is polylogarithmic in the size of the network. This trade-off between communication and time complexity motivated us to pick the algorithm \textit{quorum} for comparison. This algorithm due to Ben-Or et al., has a time complexity of $O(logn)$ although it shows a quasi-polynomial communication complexity of $n^{O(logn)}$. It uses the same setting as \textit{Pull-Push} and makes use of the well-known Feige's protocol of collective coin-flipping to decide on a small committee with the same fraction of good processes as in the whole network which then runs a leader election protocol for agreement. While both these randomized algorithms attempt to improve upon the metrics for perfomance comparison, they consider worst-case scenarios when the fraction of adversarial processes would be $n/3$ and $n/4$, respecticely. On the other hand, in a real-world system, this fraction might actually really small. This motivated us to choose a deterministic algorithm for comparison which considers this fraction during the execution of its algorithm and thus provides much better results for both communication and time complexity when the number of adversarial nodes to the size of the network is really small. These experimental results will allow us to determine, the most relevant algorithms to pick keeping in mind the workload and requirements of a system, i.e., the fraction of adversarial nodes, the bandwidth requirements and the time complexity. 


Section~\ref{sec:background} gives an introduction to the various models used to solve distributed consensus problem and provides a summary of related work in this field over the years. In Section~\ref{sec:algos}, we elaborate on the three algorithms under comparison. Section~\ref{sec:eval} details the implementation and evaluates the results obtained from the experiments. This is followed by a discussion and conclusion in Section~\ref{sec:conc}.

%TODO: 1) Consensus problem
%    2) With faults - different kind of faults -> there repercussions
%    3) Why is byzantine failures important (motivate the problem)
%
%TODO: Why so many algorithms in this area? What difference is there? Why study more? Why do a survey? Different kind of algorithms - Deterministic, randomized, almost everywhere
%
%TODO: What am I doing? What am I trying to find out? Give outline of paper
%
%ACID
%
%reliability, consistency, availability
%
%SAFETY and LIVENESS
%
%
%TODO: Give example - Alice and Bob? - show violation of above three







