
\subsection{Discussion}

As can be seen from the results above, according to the requirements and resources available, each algorithm performances differently. The first thing to consider before implementation is what resources we have and how can we design the system such that we get optimal results for the available resources. Implementing the testbed framework on a cluster allowed us to create real-time scenarios. We considered different byzantine behaviors for each algorithm and its consequences. To report on the number of bits sent per process in the worst case, we considered byzantine processes that were trying to flood the network. In this scenario, among the three algorithms we consider, algorithm \textit{Pull-Push} performs the best generally. However, in the case of a small network with number of processes lower than $32$ and a low fault percentage - approximately less than $10\%$, algorithm \textit{EIG} performs better since it considers the number of faults in its protocol. 

If we were to consider a network with its size showing high variance over time, algorithm \textit{Pull-Push} has the advantage that number of bits sent per node remains the same if the increase in size is within the next power of $2$. For strict bandwidth constraints, this allows high flexibility to change the size of the network. On the other hand, if we were to look at networks which did not change in size but had varying fault ratios, algorithm \textit{Quorum} inhibited varying number of byzantine processes from changing the communication complexity much. This, however, is restricted to networks with high bandwidth in the first place. Our modified version of algorithm \textit{EIG} showed this characteristic as well. The number of bits sent per node increased very minimally on increasing the fault ratio and also performed much better when compared to \textit{Quorum} or \textit{EIG} as can be seen in Figure ~\ref{fig:comp}.

Furthermore, the implementation results demonstrated the trade-off between the number of communication bits and the number of rounds. Algorithm \textit{Quorum} terminated in lower number of rounds than \textit{Pull-Push} for all network sizes and fault ratios. This can be attributed to its highly parallel protocol. Algorithm \textit{EIG} displayed growth proportional to the size of the network, and performed well only for very low fault ratio of $<10\%$. These trends were reflected in the latency results as well when we compared the elapsed real time. However, the total CPU time utilization increased rapidly for \textit{Quorum} due to the exponential increase in the number of sub-protocols executed in parallel as the network size increased.

In the case of a denial of service attack, an increasing ratio of faulty processes reduced the communication overhead instead of increasing it. Crash failures also reported similar results. If the faulty processes sent out only arbitrary messages, the algorithms executed correctly without hampering the communication cost much when the ratio of byzantine processes was increased.

To further optimize the performance, one can improve certain tasks such as sending a larger message instead of many smaller messages or executing parallel tasks on multi-core machines. Another optimization that would have improved the running time of the system would be to use UDP connections instead of TCP since they take up less resources and provide lower overhead. Even though UDP connections do not guarantee message delivery, for a small system it could still be considered highly reliable. The rationale behind using TCP connections for this testbed framework was to model and understand implementation issues for more realistic distributed systems, which could have peers separated by geographical distance, requiring greater reliability. 

An analysis of the three algorithms and their performance for a wide range of number of processes and faults shows that communication of each process with fewer number of processes yields good results instead of all-to-all communication. This inhibits byzantine processes from influencing values of too many good processes. It is also important that requests from byzantine processes be throttled at an early stage. The good performance of the deterministic algorithm for small fault ratios shows that it is important to consider this factor when designing an algorithm.  Communication between multiple sets of quorums allows parallel tasks to be executed and gives good latency results. The combined use of these techniques could help us design improved algorithms to solve the problem of distributed consensus. 



\section{Conclusion}
\label{sec:conc}
In real-world systems, achieving distributed consensus has become increasingly important. In most cases, consensus is a small but frequently used sub-component of a larger protocol such as in state machine replication protocols or in distributed databases. Thus, understanding the performance of algorithms for various scenarios occurring in real-time is essential to the overall performance of such systems. One needs to consider implementation issues that come along with any of these algorithms and not only their theoretical results. 

In this paper, we focused on implementation and analysis of three recently proposed algorithms with best results for their respective agendas. An Exponential Information Gathering protocol for consensus \cite{KM13} (algorithm \textit{EIG}) showed that deterministic algorithms have come a long way since the early results. We further improved upon this algorithm for better results. In general the randomized algorithm \textit{Pull-Push} \cite{BGH13}, performed better than the other two in terms of communication complexity. When latency was considered, as can be seen in Fig. \ref{fig:elapsed}, algorithm \textit{Quorum} \cite{BPV06} performed better. In real-time situations, as the number of processes in a network increase the probability of having faulty processes in the network naturally increases. Hence, even though algorithm \textit{EIG} shows better performance when the fault ratio is small, under high fault ratio the performance degrades. Using the results we were able to understand various scenarios under which different algorithms perform differently.
